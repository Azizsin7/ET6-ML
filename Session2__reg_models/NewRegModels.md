# Discover New Regression Models
---

In previous unit, we looked at fitting a straight line to data points. However, regression can fit many kinds of relationships, including those with multiple factors and those where the importance of one factor depends on another.

# Experimenting with models
---
Regression models are often chosen because they work with small data samples, are robust, easy to interpret, and a variety exist.

**Linear regression** is the simplest form of regression, with no limit to the number of features used. Linear regression comes in many forms, often named by the number of features used and the shape of the curve that fits.

**Decision trees** take a step-by-step approach to predicting a variable. If we think of our bicycle example, the decision tree might be first split examples between ones that are during Spring/Summer and Autumn/Winter, make a prediction based on the day of the week. Spring/Summer-Monday might have a bike-rental rate of 100 per day, while Autumn/Winter-Monday might have a rental rate of 20 per day.

**Ensemble algorithms** construct not just one decision tree, but a large number of trees, allowing better predictions on more complex data. Ensemble algorithms, such as Random Forest, are widely used in machine learning and data science due to their strong prediction abilities.

---

## Try It Yourself

Data scientists often **experiment with multiple models** to see which performs best on a given problem.

In the following exercise, youâ€™ll try out a few different models and compare their performance on the **same dataset**.

---

### Open in Google Colab

Click below to launch the notebook and experiment with model training and comparison:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1owppMYGhRs9sgOqen9ODF1nKINIsS40n)

---
